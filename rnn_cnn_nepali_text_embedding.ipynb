{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrIj7uZvEzzv"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj1Tm_LMPdt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4KD6lvSM2lS",
        "outputId": "fc0ed727-e5d3-4df1-e723-ef8723e4bcfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-03 03:11:43--  https://github.com/Bhandari007/DCGAN/raw/main/translated_descriptions.pickle\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Bhandari007/DCGAN/main/translated_descriptions.pickle [following]\n",
            "--2023-03-03 03:11:44--  https://raw.githubusercontent.com/Bhandari007/DCGAN/main/translated_descriptions.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819115 (1.7M) [application/octet-stream]\n",
            "Saving to: ‘translated_descriptions.pickle’\n",
            "\n",
            "translated_descript 100%[===================>]   1.73M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-03-03 03:11:44 (29.2 MB/s) - ‘translated_descriptions.pickle’ saved [1819115/1819115]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/Bhandari007/DCGAN/raw/main/translated_descriptions.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbnA3wirNOFE"
      },
      "source": [
        "## Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncYhna3fhLme"
      },
      "outputs": [],
      "source": [
        "text_description = pd.read_pickle(\"translated_descriptions.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIvxvBSrlstP",
        "outputId": "e79e39ff-bc4a-4046-f5da-555ff946c84a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1056"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OizOA35TAPif"
      },
      "source": [
        "## Description of 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApJaFtI4CTz4",
        "outputId": "4a987b74-59e9-4d64-8083-ce00fb9d9f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['चराको टाउको यसको शरीरतर्फ लाग्छ र चरा खैरो रंगको छ।',\n",
              " 'यस चराको खैरो घाँटी, टाउको, पखेटा र पछाडि, यसको बिलको वरिपरि सेतो छ, र लामो अग्लो बिल जुन यसको टिपमा छ।',\n",
              " 'यो चरिंग लामो घुमाइएको चुच्चो र गाढा आँखा घण्टीहरूको साथ रंगमा खैरो छ।',\n",
              " 'यो चरा केही सेतो संग खैरो छ र लामो, पुरानो चुच्चो छ।',\n",
              " 'यो वेबरेड खुट्टा र लामो अलि हुकिएको बिल संग ठोस खैरो चरा हो।',\n",
              " 'यो विशेष चराको खैरो शरीर र खैरो बिल छ',\n",
              " 'खैरो रंगीन अल्बर्सरको आधारमा सेतो औंठीको, सेतो बकवास र सेतो आलु।',\n",
              " 'यो चराको पखेटा छ जुन खैरो छ र ठूलो बिल छ',\n",
              " 'यो चरा खैरो रंगमा छ, ठूलो घुमाइएको चुच्चोको साथ।',\n",
              " 'एक खैरो रंग र लामो चुच्चो संग एक ठूलो चरा।']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_description[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q5c914ll9C9"
      },
      "source": [
        "### Make a text corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xZzu5kHmBIE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "text_corpus = \"\"\n",
        "for sentence in text_description:\n",
        "  for word in sentence:\n",
        "    text_corpus+=word\n",
        "\n",
        "text_corpus = text_corpus.replace(\"\\n\", \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ob5Y3sieCVo3",
        "outputId": "6f755003-8cc3-4cc7-c662-a3adb0a91e60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'मध्यम आकारको बर्डको गाढा खैरो रंग छ, कालो तलतिर घुमाइएको चुच्चो, र लामो पखेटा।चरा गाढा खैरो खैरो छ र'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_corpus[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4uGkciJCYN2"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zTW14vPCx5N",
        "outputId": "ad409c4f-f393-4915-a09c-d70c34c1f52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 690249 characters\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of text: {len(text_corpus)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZmqXIlDCdp",
        "outputId": "b8faa9ae-f5dc-4de5-b091-a189059f5886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131 unique characters\n"
          ]
        }
      ],
      "source": [
        "vocab = sorted(set(text_corpus))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pKSrPu4C2VT",
        "outputId": "743b5e71-60f2-4700-a115-dbecb3f56898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', '।']\n"
          ]
        }
      ],
      "source": [
        "print(vocab[90:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw-xE6VbDNLo"
      },
      "source": [
        "# Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu7TY2l2GExR"
      },
      "source": [
        "## Vectorize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZAv40qdGHsP",
        "outputId": "e8720236-0db8-41a3-c071-0f96ffd10801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'\\xe0\\xa4\\x9a', b'\\xe0\\xa4\\xb0', b'\\xe0\\xa4\\xbe', b'\\xe0\\xa4\\x95',\n",
              "  b'\\xe0\\xa5\\x8b'],\n",
              " [b'\\xe0\\xa4\\xae', b'\\xe0\\xa5\\x81', b'\\xe0\\xa4\\x95', b'\\xe0\\xa5\\x81',\n",
              "  b'\\xe0\\xa4\\x9f']]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = [\"चराको\", \"मुकुट\"]\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding = 'UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t58sx3rGZGs"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC4cOPrtGefn",
        "outputId": "5b0d83c3-b6dc-4e95-8c3f-4af91136662a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[90, 111, 119, 85, 128],\n",
              " [109, 122, 85, 122, 95]]>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg2LpUc4Ggo8"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X4XDZkgGifn",
        "outputId": "4b14bd48-6744-405b-9947-79c4f18cf3ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'\\xe0\\xa4\\x9a', b'\\xe0\\xa4\\xb0', b'\\xe0\\xa4\\xbe', b'\\xe0\\xa4\\x95',\n",
              "  b'\\xe0\\xa5\\x8b'],\n",
              " [b'\\xe0\\xa4\\xae', b'\\xe0\\xa5\\x81', b'\\xe0\\xa4\\x95', b'\\xe0\\xa5\\x81',\n",
              "  b'\\xe0\\xa4\\x9f']]>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m1ksLs1GlOF",
        "outputId": "1239c9c2-48a4-4eb2-db09-381a1b8a28df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b',\n",
              "       b'\\xe0\\xa4\\xae\\xe0\\xa5\\x81\\xe0\\xa4\\x95\\xe0\\xa5\\x81\\xe0\\xa4\\x9f'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7DY_VJvGm3r"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk-cu3kyGq8o"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io0wfHczGt6l"
      },
      "source": [
        "### Create training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFPPKDa7Gxbo",
        "outputId": "33aa8ca1-626b-4d64-ea06-5bbac81efaad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(690249,), dtype=int64, numpy=array([109, 103, 130, ..., 111, 119, 131])>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text_corpus, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehUSdAYmGzGE"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLk4A9mqG3gP",
        "outputId": "043ff306-1041-45c8-f354-a9dbb1cc6602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "म\n",
            "ध\n",
            "्\n",
            "य\n",
            "म\n",
            " \n",
            "आ\n",
            "क\n",
            "ा\n",
            "र\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIy8geJpG4zM"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTf0mABbG8iz",
        "outputId": "04ee67a3-8aab-4344-8ce0-001494469b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe0\\xa4\\xae' b'\\xe0\\xa4\\xa7' b'\\xe0\\xa5\\x8d' b'\\xe0\\xa4\\xaf'\n",
            " b'\\xe0\\xa4\\xae' b' ' b'\\xe0\\xa4\\x86' b'\\xe0\\xa4\\x95' b'\\xe0\\xa4\\xbe'\n",
            " b'\\xe0\\xa4\\xb0' b'\\xe0\\xa4\\x95' b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\xac'\n",
            " b'\\xe0\\xa4\\xb0' b'\\xe0\\xa5\\x8d' b'\\xe0\\xa4\\xa1' b'\\xe0\\xa4\\x95'\n",
            " b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\x97' b'\\xe0\\xa4\\xbe' b'\\xe0\\xa4\\xa2'\n",
            " b'\\xe0\\xa4\\xbe' b' ' b'\\xe0\\xa4\\x96' b'\\xe0\\xa5\\x88' b'\\xe0\\xa4\\xb0'\n",
            " b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\xb0' b'\\xe0\\xa4\\x82' b'\\xe0\\xa4\\x97' b' '\n",
            " b'\\xe0\\xa4\\x9b' b',' b' ' b'\\xe0\\xa4\\x95' b'\\xe0\\xa4\\xbe' b'\\xe0\\xa4\\xb2'\n",
            " b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\xa4' b'\\xe0\\xa4\\xb2' b'\\xe0\\xa4\\xa4'\n",
            " b'\\xe0\\xa4\\xbf' b'\\xe0\\xa4\\xb0' b' ' b'\\xe0\\xa4\\x98' b'\\xe0\\xa5\\x81'\n",
            " b'\\xe0\\xa4\\xae' b'\\xe0\\xa4\\xbe' b'\\xe0\\xa4\\x87' b'\\xe0\\xa4\\x8f'\n",
            " b'\\xe0\\xa4\\x95' b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\x9a' b'\\xe0\\xa5\\x81'\n",
            " b'\\xe0\\xa4\\x9a' b'\\xe0\\xa5\\x8d' b'\\xe0\\xa4\\x9a' b'\\xe0\\xa5\\x8b' b',' b' '\n",
            " b'\\xe0\\xa4\\xb0' b' ' b'\\xe0\\xa4\\xb2' b'\\xe0\\xa4\\xbe' b'\\xe0\\xa4\\xae'\n",
            " b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\xaa' b'\\xe0\\xa4\\x96' b'\\xe0\\xa5\\x87'\n",
            " b'\\xe0\\xa4\\x9f' b'\\xe0\\xa4\\xbe' b'\\xe0\\xa5\\xa4' b'\\xe0\\xa4\\x9a'\n",
            " b'\\xe0\\xa4\\xb0' b'\\xe0\\xa4\\xbe' b' ' b'\\xe0\\xa4\\x97' b'\\xe0\\xa4\\xbe'\n",
            " b'\\xe0\\xa4\\xa2' b'\\xe0\\xa4\\xbe' b' ' b'\\xe0\\xa4\\x96' b'\\xe0\\xa5\\x88'\n",
            " b'\\xe0\\xa4\\xb0' b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\x96' b'\\xe0\\xa5\\x88'\n",
            " b'\\xe0\\xa4\\xb0' b'\\xe0\\xa5\\x8b' b' ' b'\\xe0\\xa4\\x9b' b' ' b'\\xe0\\xa4\\xb0'\n",
            " b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GXK_K74G-P_",
        "outputId": "852d9b4c-816f-45d9-d1f1-a1b09664e455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\\xe0\\xa4\\xae\\xe0\\xa4\\xa7\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xae \\xe0\\xa4\\x86\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xac\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xa1\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0\\xe0\\xa4\\x82\\xe0\\xa4\\x97 \\xe0\\xa4\\x9b, \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xa4\\xe0\\xa4\\xb2\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf\\xe0\\xa4\\xb0 \\xe0\\xa4\\x98\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa4\\xbe\\xe0\\xa4\\x87\\xe0\\xa4\\x8f\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b, \\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b \\xe0\\xa4\\xb0 '\n",
            "b'\\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xac\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8d\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xac\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb0 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xab\\xe0\\xa5\\x8d\\xe0\\xa4\\xb2\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\x9f \\xe0\\xa4\\x86\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa4\\xb0\\xe0\\xa5\\xa4\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xac\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x89\\xe0\\xa4\\xa8 \\xe0\\xa4\\xb6\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\x81\\xe0\\xa4\\x96\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0\\xe0\\xa5\\x82, \\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xa4\\xe0\\xa5\\x8b \\xe0\\xa4\\xb8\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa4\\xa8 \\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb5\\xe0\\xa4\\xbe\\xe0\\xa4\\x81\\xe0\\xa4\\x96\\xe0\\xa4\\xb9\\xe0\\xa4\\xb0\\xe0\\xa5\\x82 \\xe0\\xa4\\xb0 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe'\n",
            "b'\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xa7\\xe0\\xa5\\x81\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b\\xe0\\xa4\\xaf\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x85\\xe0\\xa4\\x81\\xe0\\xa4\\xa7\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0\\xe0\\xa4\\xa8\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb6\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0 color \\xe0\\xa4\\x9b, \\xe0\\xa4\\xac\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x86\\xe0\\xa4\\xa7\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb5\\xe0\\xa4\\xb0\\xe0\\xa4\\xbf\\xe0\\xa4\\xaa\\xe0\\xa4\\xb0\\xe0\\xa4\\xbf \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xa8\\xe0\\xa5\\x8b \\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xa4\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xbe\\xe0\\xa4\\x9a\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xa5\\xe0\\xa5\\xa4\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xa7'\n",
            "b'\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x88 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0 \\xe0\\xa4\\xa0\\xe0\\xa5\\x82\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe, \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xa5\\xe0\\xa5\\x88 \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xb6\\xe0\\xa4\\xb0\\xe0\\xa5\\x80\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b\\xe0\\xa5\\xa4\\xe0\\xa4\\xaf\\xe0\\xa5\\x8b \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe, \\xe0\\xa4\\xaa\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9b\\xe0\\xa4\\xb0, \\xe0\\xa4\\xaa\\xe0\\xa4\\x9b\\xe0\\xa4\\xbe\\xe0\\xa4\\xa1\\xe0\\xa4\\xbf \\xe0\\xa4\\xb0 \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b'\n",
            "b'\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb8\\xe0\\xa4\\xbe\\xe0\\xa4\\xa5 \\xe0\\xa4\\x85\\xe0\\xa4\\xb2\\xe0\\xa5\\x8d\\xe0\\xa4\\xac\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0 \\xe0\\xa4\\xb9\\xe0\\xa5\\x8b, \\xe0\\xa4\\xb0 \\xe0\\xa4\\xaf\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x86\\xe0\\xa4\\xa7\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\xae\\xe0\\xa4\\xbe \\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xa4\\xe0\\xa5\\x8b \\xe0\\xa4\\x94\\xe0\\xa4\\x82\\xe0\\xa4\\xa0\\xe0\\xa5\\x80 \\xe0\\xa4\\x9b\\xe0\\xa5\\xa4\\xe0\\xa4\\xaf\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x82\\xe0\\xa4\\xa6\\xe0\\xa4\\xbe\\xe0\\xa4\\x9c \\xe0\\xa4\\xb0 \\xe0\\xa4\\xaf\\xe0\\xa4\\xb8\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b,'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiZ0YbHxHAX8"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_62DDF2HDF9",
        "outputId": "e2861bb7-7e07-446f-f32e-6a912518d21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['त', 'ु', 'ल', 'न', 'ा', 'म'], ['ु', 'ल', 'न', 'ा', 'म', 'ा'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"तुलनामा\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8jwDzhVHEUy"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQWx7-vLHF8N",
        "outputId": "59cebe27-ca8a-455a-fd08-1784bb4113cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'\\xe0\\xa4\\xae\\xe0\\xa4\\xa7\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xae \\xe0\\xa4\\x86\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xac\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xa1\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0\\xe0\\xa4\\x82\\xe0\\xa4\\x97 \\xe0\\xa4\\x9b, \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xa4\\xe0\\xa4\\xb2\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf\\xe0\\xa4\\xb0 \\xe0\\xa4\\x98\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa4\\xbe\\xe0\\xa4\\x87\\xe0\\xa4\\x8f\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b, \\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b \\xe0\\xa4\\xb0'\n",
            "Target: b'\\xe0\\xa4\\xa7\\xe0\\xa5\\x8d\\xe0\\xa4\\xaf\\xe0\\xa4\\xae \\xe0\\xa4\\x86\\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb0\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xac\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xa1\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\xb0\\xe0\\xa4\\x82\\xe0\\xa4\\x97 \\xe0\\xa4\\x9b, \\xe0\\xa4\\x95\\xe0\\xa4\\xbe\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xa4\\xe0\\xa4\\xb2\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf\\xe0\\xa4\\xb0 \\xe0\\xa4\\x98\\xe0\\xa5\\x81\\xe0\\xa4\\xae\\xe0\\xa4\\xbe\\xe0\\xa4\\x87\\xe0\\xa4\\x8f\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b, \\xe0\\xa4\\xb0 \\xe0\\xa4\\xb2\\xe0\\xa4\\xbe\\xe0\\xa4\\xae\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa4\\x96\\xe0\\xa5\\x87\\xe0\\xa4\\x9f\\xe0\\xa4\\xbe\\xe0\\xa5\\xa4\\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe \\xe0\\xa4\\x97\\xe0\\xa4\\xbe\\xe0\\xa4\\xa2\\xe0\\xa4\\xbe \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x96\\xe0\\xa5\\x88\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b \\xe0\\xa4\\xb0 '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzYJ1X-aHNYW",
        "outputId": "d5a5788b-4ad0-4632-9023-d81cdc9ef126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-W6RW82HP4G"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gmp9qQbHTwD"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mGRTWgeHWCH"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKQXOjsoHXrJ"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si37jGF6HZTk",
        "outputId": "7d765e0a-d847-4349-97d3-b6d1e2228198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 132) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7CoWdRYHbtr",
        "outputId": "403114a2-f290-40fc-97eb-adc10211daae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  135168    \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  31080     \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  1452      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,700\n",
            "Trainable params: 167,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxX5XBp9HfCk"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__choiDHioV",
        "outputId": "0123f09c-95da-4227-eb04-cd3903c2c6e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 89,  79, 123,  71, 124,  50,  63,  49,  55,  69,  74, 124,  61,\n",
              "        61, 107, 108,   7,  45,  23,  74,  49,  29,  30,  76, 115,  56,\n",
              "        99,  78,  59, 107,  89,  51, 107,  93,  63,  70,  83,   8,  63,\n",
              "       101, 119,  50, 114, 128,  40, 129,  94,  84,  51,  77,  58, 131,\n",
              "        82,  80,   0,  13,  36,  56,  84, 123,  99,  90, 128,  22,  66,\n",
              "       110,  95,  47,  72, 110,  16, 115,  48,  69, 119,  25,  48,  13,\n",
              "         6,  97,  93,  41,  53, 112, 123,  42,  71, 120, 112, 126,   0,\n",
              "       116,   7,  92,  64, 126,  87,  48,  98,  97])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H2bKtL-HklH",
        "outputId": "9ea9661a-fd06-4796-87e4-99b81ea10b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'\\xe0\\xa5\\x87\\xe0\\xa4\\xb0\\xe0\\xa5\\x88 \\xe0\\xa4\\x9b\\xe0\\xa5\\x8b\\xe0\\xa4\\x9f\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa5\\x81\\xe0\\xa4\\x9a\\xe0\\xa5\\x8d\\xe0\\xa4\\x9a\\xe0\\xa5\\x8b \\xe0\\xa4\\x9b\\xe0\\xa5\\xa4\\xe0\\xa4\\xaf\\xe0\\xa5\\x8b \\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\x89\\xe0\\xa4\\x9c\\xe0\\xa5\\x8d\\xe0\\xa4\\x9c\\xe0\\xa5\\x8d\\xe0\\xa4\\xb5\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb8\\xe0\\xa5\\x81\\xe0\\xa4\\xa8\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa4\\xb2\\xe0\\xa4\\xbe \\xe0\\xa4\\xac\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2 \\xe0\\xa4\\xb0 \\xe0\\xa4\\x8f\\xe0\\xa4\\x95 \\xe0\\xa4\\x9a\\xe0\\xa4\\xae\\xe0\\xa5\\x8d\\xe0\\xa4\\x95\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa5\\x8b \\xe0\\xa4\\xb8\\xe0\\xa5\\x87\\xe0\\xa4\\xa4\\xe0\\xa5\\x8b \\xe0\\xa4\\x85\\xe0\\xa4\\xaf\\xe0\\xa4\\xb0\\xe0\\xa5\\x8b\\xe0\\xa4\\xb2\\xe0\\xa4\\xbf\\xe0\\xa4\\x82\\xe0\\xa4\\x97 \\xe0\\xa4\\x9b\\xe0\\xa4\\xaf\\xe0\\xa5\\x8b \\xe0\\xa4\\xb5\\xe0\\xa4\\xbf\\xe0\\xa4\\xb6\\xe0\\xa5\\x87\\xe0\\xa4\\xb7 \\xe0\\xa4\\x9a\\xe0\\xa4\\xb0\\xe0\\xa4\\xbe\\xe0\\xa4\\x95\\xe0\\xa5\\x8b \\xe0\\xa4\\xaa\\xe0\\xa5\\x87\\xe0\\xa4\\x9f \\xe0\\xa4\\x9b \\xe0\\xa4\\x9c\\xe0\\xa5\\x81\\xe0\\xa4\\xa8 '\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xe0\\xa4\\x99\\xe0\\xa4\\x88\\xe0\\xa5\\x82\\xc3\\x8f\\xe0\\xa5\\x83gufl\\xc2\\xbd\\xe0\\xa4\\x82\\xe0\\xa5\\x83ss\\xe0\\xa4\\xac\\xe0\\xa4\\xad)bE\\xe0\\xa4\\x82fLN\\xe0\\xa4\\x85\\xe0\\xa4\\xb7m\\xe0\\xa4\\xa3\\xe0\\xa4\\x87p\\xe0\\xa4\\xac\\xe0\\xa4\\x99h\\xe0\\xa4\\xac\\xe0\\xa4\\x9du\\xc2\\xbf\\xe0\\xa4\\x93,u\\xe0\\xa4\\xa5\\xe0\\xa4\\xbeg\\xe0\\xa4\\xb6\\xe0\\xa5\\x8bY\\xe0\\xa5\\x8c\\xe0\\xa4\\x9e\\xe0\\xa4\\x94h\\xe0\\xa4\\x86o\\xe0\\xa5\\xa4\\xe0\\xa4\\x8f\\xe0\\xa4\\x89[UNK]2Tm\\xe0\\xa4\\x94\\xe0\\xa5\\x82\\xe0\\xa4\\xa3\\xe0\\xa4\\x9a\\xe0\\xa5\\x8bDx\\xe0\\xa4\\xaf\\xe0\\xa4\\x9fd\\xc3\\xaf\\xe0\\xa4\\xaf:\\xe0\\xa4\\xb7e\\xc2\\xbd\\xe0\\xa4\\xbeGe2(\\xe0\\xa4\\xa1\\xe0\\xa4\\x9dZj\\xe0\\xa4\\xb2\\xe0\\xa5\\x82_\\xc3\\x8f\\xe0\\xa4\\xbf\\xe0\\xa4\\xb2\\xe0\\xa5\\x88[UNK]\\xe0\\xa4\\xb8)\\xe0\\xa4\\x9cv\\xe0\\xa5\\x88\\xe0\\xa4\\x97e\\xe0\\xa4\\xa2\\xe0\\xa4\\xa1'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Si10AXL6rp"
      },
      "source": [
        "Input: \"प्वाँखभएको।योएउटासेतोरकालोचराहोजसकोसानोचुचुरोरसेतोआँखाहुन्छ।एउटासानोआकारकोचराजस\" \n",
        "<br>\n",
        "Next Char Predictions: \"ृखऊभमभउएुएथधइ्यरडनव्।टकःबऊडेअतोणऊिुनूएचोँौीङराङीैयघकघअऊेहअनेमग।तोँागझढइहवँडऔीएजगदेणनचसप\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV2qABwXHnT4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZDd51LeHtWD"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhXMnxlQHuST",
        "outputId": "67aebedb-ca82-4f58-c54e-24436373596d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 132)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.883576, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7nJrAU1Hvmj",
        "outputId": "0a2f2a6c-ce32-4c12-87dc-ca0456b44eec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "132.1022"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eo1SSGUHyF-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T-6iVByH0Ku"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n1ukN28H1ph"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDVFHogaH4id"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3-ve1wrH5tM",
        "outputId": "51f77dbc-d26e-4359-840f-7262e6d3c42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "106/106 [==============================] - 11s 31ms/step - loss: 4.0951\n",
            "Epoch 2/50\n",
            "106/106 [==============================] - 3s 17ms/step - loss: 3.3731\n",
            "Epoch 3/50\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 3.0768\n",
            "Epoch 4/50\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 2.8310\n",
            "Epoch 5/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 2.6541\n",
            "Epoch 6/50\n",
            "106/106 [==============================] - 2s 11ms/step - loss: 2.5049\n",
            "Epoch 7/50\n",
            "106/106 [==============================] - 5s 9ms/step - loss: 2.3701\n",
            "Epoch 8/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 2.2549\n",
            "Epoch 9/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 2.1701\n",
            "Epoch 10/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 2.1019\n",
            "Epoch 11/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 2.0479\n",
            "Epoch 12/50\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 2.0029\n",
            "Epoch 13/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.9660\n",
            "Epoch 14/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.9347\n",
            "Epoch 15/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.9041\n",
            "Epoch 16/50\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 1.8723\n",
            "Epoch 17/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.8454\n",
            "Epoch 18/50\n",
            "106/106 [==============================] - 3s 9ms/step - loss: 1.8224\n",
            "Epoch 19/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.7954\n",
            "Epoch 20/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.7711\n",
            "Epoch 21/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.7506\n",
            "Epoch 22/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.7311\n",
            "Epoch 23/50\n",
            "106/106 [==============================] - 3s 9ms/step - loss: 1.7129\n",
            "Epoch 24/50\n",
            "106/106 [==============================] - 3s 8ms/step - loss: 1.6978\n",
            "Epoch 25/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.6852\n",
            "Epoch 26/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.6727\n",
            "Epoch 27/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.6602\n",
            "Epoch 28/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.6485\n",
            "Epoch 29/50\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 1.6393\n",
            "Epoch 30/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.6296\n",
            "Epoch 31/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.6205\n",
            "Epoch 32/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.6130\n",
            "Epoch 33/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.6057\n",
            "Epoch 34/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5990\n",
            "Epoch 35/50\n",
            "106/106 [==============================] - 3s 8ms/step - loss: 1.5930\n",
            "Epoch 36/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.5877\n",
            "Epoch 37/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5815\n",
            "Epoch 38/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.5769\n",
            "Epoch 39/50\n",
            "106/106 [==============================] - 4s 8ms/step - loss: 1.5722\n",
            "Epoch 40/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.5681\n",
            "Epoch 41/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5633\n",
            "Epoch 42/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.5593\n",
            "Epoch 43/50\n",
            "106/106 [==============================] - 3s 10ms/step - loss: 1.5544\n",
            "Epoch 44/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5511\n",
            "Epoch 45/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.5472\n",
            "Epoch 46/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5440\n",
            "Epoch 47/50\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 1.5401\n",
            "Epoch 48/50\n",
            "106/106 [==============================] - 2s 6ms/step - loss: 1.5374\n",
            "Epoch 49/50\n",
            "106/106 [==============================] - 3s 9ms/step - loss: 1.5338\n",
            "Epoch 50/50\n",
            "106/106 [==============================] - 2s 8ms/step - loss: 1.5300\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LvwFa8LH6mX",
        "outputId": "088a105a-9385-48e2-b1ba-b0488f03584f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(132, 1024)\n"
          ]
        }
      ],
      "source": [
        "print(model.layers[0].get_weights()[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mqdp8n1J6o4"
      },
      "outputs": [],
      "source": [
        "embeddings = model.get_layer('embedding').get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6vOrHEvCgti",
        "outputId": "97f98af3-cae2-47f2-e341-85afb54ee0a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(132, 1024)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char_embeddings = embeddings\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCACkL4tUz14"
      },
      "outputs": [],
      "source": [
        "with open(\"embeddings.pickle\" , 'wb') as f:\n",
        "  pickle.dump(embeddings, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTE5RuV3ReHA"
      },
      "source": [
        "### Generate Embeddings for Train Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu7W_QwWnS0Q",
        "outputId": "06d7dc22-bd6a-45f2-b08a-b0cfb424d094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = ids_from_chars.get_vocabulary()\n",
        "len(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oVjAkL3D_QG"
      },
      "source": [
        "### Combining tokens and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEDuIcY7ED2n"
      },
      "outputs": [],
      "source": [
        "token_embeddings = dict()\n",
        "for index,token in enumerate(tokens):\n",
        "  token_embeddings[token] = embeddings[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOhiDhJxLA8A"
      },
      "source": [
        "#### reverse dictionary lookup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skwmm6VSRkbn"
      },
      "outputs": [],
      "source": [
        "char_to_index = {}\n",
        "for index,char in enumerate(tokens):\n",
        "  char_to_index[char] = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HttZk3uGOupt"
      },
      "outputs": [],
      "source": [
        "def average_word_embeddings(word, char_embeddings, char_to_index):\n",
        "  \"\"\"\n",
        "  Average the character embeddings for a word\n",
        "\n",
        "  Arguments:\n",
        "    word -- the word for which we want to generate the embedding\n",
        "    char_embeddngs -- a numpy array of shape (num_characters, embedding_size) containing the character embeddings\n",
        "    char_to_index -- a dictionary that maps each character to its index in char_embeddings\n",
        "  \n",
        "  Returns:\n",
        "    word_embedding -- the averaged character embeddings for the word\n",
        "  \"\"\"\n",
        "  # char_indices = [char_to_index[char] for char in word]\n",
        "  char_indices = list()\n",
        "  for char in word:\n",
        "    if char not in tokens:\n",
        "      char = \"[UNK]\"\n",
        "    char_indices.append(char_to_index[char])\n",
        "  word_embedding = np.mean(char_embeddings[char_indices], axis=0)\n",
        "  return word_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk4JOQKrCqi6"
      },
      "source": [
        "### TESTING:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa7TP0BjOsIV",
        "outputId": "d5cffc9d-a067-4ffb-b9d2-31971caa29af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.04833474,  0.02841681, -0.02949674, ...,  0.10344802,\n",
              "        0.06044192, -0.03551155], dtype=float32)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_word_embeddings(\"सुन्तला1\", char_embeddings, char_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOzuK-hyOmMT"
      },
      "outputs": [],
      "source": [
        "def average_sentence_embeddings(sentence):\n",
        "  \"\"\"\n",
        "  Average the word embeddings for a sentence\n",
        "\n",
        "  Arguments:\n",
        "    sentence -- the sentence for which we want to generate the embedding\n",
        "  \"\"\"\n",
        "  text_embeddings = list()\n",
        "  sentence_embeddings = list()\n",
        "  sentence = sentence.split(\" \")\n",
        "  sentence_indices = list()\n",
        "  for index, word in enumerate(sentence):\n",
        "    if word not in tokens:\n",
        "      word = \"[UNK]\"\n",
        "    sentence_indices.append(index)\n",
        "    embeddings = average_word_embeddings(word, char_embeddings, char_to_index)\n",
        "    sentence_embeddings.append(embeddings)\n",
        "  text_embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
        "  return text_embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aghzrR_OrgcR",
        "outputId": "17312125-6d0e-40e9-8966-6a8c61e8cd5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.06284051, -0.0250615 , -0.04158952, ..., -0.02211666,\n",
              "       -0.02491022,  0.01588372], dtype=float32)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_sentence_embeddings(\"सुन्तला र पहेँलो दाग भएको सानो कालो चरा, छोटो  टार्सस र मध्यम चुचुरोमा\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmFAiApyTnbl",
        "outputId": "c6f9fc68-a21d-40eb-8e04-5b0e4ce49ef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([-0.05196976, -0.03763029, -0.04089294, ..., -0.01561808,\n",
              "        -0.03914392,  0.02317065], dtype=float32)]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_sentence_embeddings(\"यो प्रायः कालो चराको पूरै शरीरमा कालो हुन्छ बाहेक कभरट्स ट्यानको रेखाको साथ चम्किलो रातो हुन्छ।\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfEnl5QdFsOR"
      },
      "source": [
        "## Generate Embeddings for Text Descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-ilk3T1qYA"
      },
      "outputs": [],
      "source": [
        "text_embeddings = list()\n",
        "for paragraphs in text_description:\n",
        "  sentence_embeddings = list()\n",
        "  for sentence in paragraphs:\n",
        "    embed = average_sentence_embeddings(sentence)[0]\n",
        "    sentence_embeddings.append(embed)\n",
        "  sentence_embeddings = np.array(sentence_embeddings)\n",
        "  text_embeddings.append(sentence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T68TtwbXRM6m",
        "outputId": "24833a69-095b-4c7b-ccf3-a7a9345b6a7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1056"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wxEIxOWTu76",
        "outputId": "949ab575-9c8b-44c8-ee38-17f187121ea3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 1024)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_embeddings[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugzjWLRCGxq7",
        "outputId": "6ed4b4ff-2b94-481c-e91c-cda0a9732274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "779 - 543"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT9JezXzGC3D"
      },
      "source": [
        "## Save first 543 as train_embeddings and rest as test_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlheSb3TUKf6"
      },
      "outputs": [],
      "source": [
        "with open(\"train_embeddings.pickle\" , 'wb') as f:\n",
        "  pickle.dump(text_embeddings[:779], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t42QbHSifIpW"
      },
      "outputs": [],
      "source": [
        "with open(\"test_embeddings.pickle\" , 'wb') as f:\n",
        "  pickle.dump(text_embeddings[779:], f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
